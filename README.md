# An谩lisis de Componentes Principales (PCA) con NumPy

Este proyecto implementa desde cero el algoritmo de PCA (Principal Component Analysis) usando 煤nicamente `NumPy`, con apoyo de `pandas`, `matplotlib` y `seaborn` para carga y visualizaci贸n de datos.

El objetivo es reducir la dimensionalidad de un conjunto de datos (Iris dataset) preservando el 95% de la varianza original.

##  Estructura del proyecto

- `pca.py`: Contiene la clase `PCA` con los m茅todos:
  - `estandarizar_datos`: Estandariza los datos con media 0 y desviaci贸n est谩ndar 1.
  - `descomponer_matriz_covarianza`: Calcula la matriz de covarianza y obtiene los eigenvalores y eigenvectores.
  - `analisis_comp_princ`: Reduce la dimensionalidad de los datos conservando el 95% de la varianza.

- `tests.py`: Pruebas autom谩ticas para validar el funcionamiento correcto de cada m茅todo.

- `colab_pca.ipynb`: Notebook con el desarrollo paso a paso del an谩lisis PCA y visualizaci贸n.

##  Dataset utilizado

Se usa el conjunto de datos de *Iris* de UCI Machine Learning Repository, con 150 muestras de 3 tipos distintos de lirios y 4 caracter铆sticas por flor:

- Longitud del s茅palo
- Ancho del s茅palo
- Longitud del p茅talo
- Ancho del p茅talo

##  Requisitos

- Python 3.x
- NumPy
- Pandas
- Matplotlib
- Seaborn

Puedes instalar las dependencias con:

```bash
pip install numpy pandas matplotlib seaborn
````

##  C贸mo ejecutar
Abre el notebook colab_pca.ipynb en Google Colab o Jupyter.

Ejecuta las celdas una por una para seguir el an谩lisis PCA.

Tambi茅n puedes ejecutar los tests unitarios para validar el c贸digo:
````bash
python tests.py
````

## И Tests incluidos
El proyecto contiene pruebas autom谩ticas para:

Verificar la estandarizaci贸n de datos

Comprobar la descomposici贸n en vectores y valores propios

Validar que se conserva el 95% de la varianza en la transformaci贸n PCA

##  Licencia
Este proyecto est谩 bajo licencia MIT. Puedes usar, modificar y distribuir libremente.


